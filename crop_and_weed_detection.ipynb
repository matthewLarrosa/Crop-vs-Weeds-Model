{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, InputLayer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_crop_weeds = 'agri_data/data/'  # Update this path as necessary\n",
    "\n",
    "# Images Sizes\n",
    "img_height = 512\n",
    "img_width = 512\n",
    "\n",
    "# Defines batch size and number of epochs\n",
    "batch_size = 32\n",
    "epochs = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Images: 1300\n",
      "Total Annotations: 1300\n"
     ]
    }
   ],
   "source": [
    "images = []\n",
    "annotations = []\n",
    "\n",
    "for filename in os.listdir(dataset_crop_weeds):\n",
    "    if filename.endswith('.jpeg'):\n",
    "        image_path = os.path.join(dataset_crop_weeds, filename)\n",
    "        images.append(image_path)\n",
    "    elif filename.endswith('.txt'):\n",
    "        annotation_path = os.path.join(dataset_crop_weeds, filename)\n",
    "        annotations.append(annotation_path)\n",
    "\n",
    "print(f\"Total Images: {len(images)}\")\n",
    "print(f\"Total Annotations: {len(annotations)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images, test_images, train_annotations, test_annotations = train_test_split(images, annotations, test_size=0.2, random_state=42)\n",
    "train_images, val_images, train_annotations, val_annotations = train_test_split(train_images, train_annotations, test_size=0.1, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_image(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB\n",
    "    image = cv2.resize(image, (img_width, img_height))\n",
    "    return image / 255.0  # Normalize pixel values to [0, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_annotation(annotation_path):\n",
    "    with open(annotation_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    annotations = []\n",
    "    for line in lines:\n",
    "        class_label = int(line.strip().split()[0])  # Assuming class label is the first element\n",
    "        annotations.append(class_label)  # For binary classification\n",
    "\n",
    "    return annotations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming each annotation file contains a single integer label for binary classification\n",
    "def parse_annotation(annotation_path):\n",
    "    with open(annotation_path, 'r') as file:\n",
    "        # Read the first line to get the class label (assuming the class label is always the first piece of data on the line)\n",
    "        first_line = file.readline().strip()\n",
    "        class_label = int(first_line.split()[0])  # Extracts the class label (integer) from the line\n",
    "    return class_label\n",
    "\n",
    "# Preprocess the image and annotation data\n",
    "train_images_data = np.array([load_and_preprocess_image(img) for img in train_images])\n",
    "val_images_data = np.array([load_and_preprocess_image(img) for img in val_images])\n",
    "test_images_data = np.array([load_and_preprocess_image(img) for img in test_images])\n",
    "\n",
    "# Preprocess the image and annotation data again with the corrected parse_annotation function\n",
    "train_annotations_data = np.array([parse_annotation(ann) for ann in train_annotations])\n",
    "val_annotations_data = np.array([parse_annotation(ann) for ann in val_annotations])\n",
    "test_annotations_data = np.array([parse_annotation(ann) for ann in test_annotations])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    InputLayer(input_shape=(img_height, img_width, 3)),\n",
    "    Conv2D(32, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')  # Binary classification\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "30/30 [==============================] - 82s 3s/step - loss: 1.2570 - accuracy: 0.5096 - val_loss: 0.6934 - val_accuracy: 0.4712\n",
      "Epoch 2/10\n",
      "30/30 [==============================] - 96s 3s/step - loss: 0.6995 - accuracy: 0.5438 - val_loss: 0.6928 - val_accuracy: 0.5385\n",
      "Epoch 3/10\n",
      "30/30 [==============================] - 95s 3s/step - loss: 0.6913 - accuracy: 0.5470 - val_loss: 0.6930 - val_accuracy: 0.5192\n",
      "Epoch 4/10\n",
      "30/30 [==============================] - 85s 3s/step - loss: 0.6930 - accuracy: 0.4904 - val_loss: 0.6929 - val_accuracy: 0.5192\n",
      "Epoch 5/10\n",
      "30/30 [==============================] - 83s 3s/step - loss: 0.6917 - accuracy: 0.5267 - val_loss: 0.6922 - val_accuracy: 0.5288\n",
      "Epoch 6/10\n",
      "30/30 [==============================] - 84s 3s/step - loss: 0.6597 - accuracy: 0.6186 - val_loss: 0.7494 - val_accuracy: 0.5673\n",
      "Epoch 7/10\n",
      "30/30 [==============================] - 104s 3s/step - loss: 0.5334 - accuracy: 0.7778 - val_loss: 0.9647 - val_accuracy: 0.5096\n",
      "Epoch 8/10\n",
      "30/30 [==============================] - 109s 4s/step - loss: 0.4030 - accuracy: 0.8387 - val_loss: 1.0249 - val_accuracy: 0.5481\n",
      "Epoch 9/10\n",
      "30/30 [==============================] - 97s 3s/step - loss: 0.2631 - accuracy: 0.8846 - val_loss: 1.2785 - val_accuracy: 0.5962\n",
      "Epoch 10/10\n",
      "30/30 [==============================] - 90s 3s/step - loss: 0.2013 - accuracy: 0.9327 - val_loss: 1.3250 - val_accuracy: 0.5577\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_images_data, train_annotations_data, batch_size=batch_size, epochs=epochs, validation_data=(val_images_data, val_annotations_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 - 7s - loss: 1.3945 - accuracy: 0.4885 - 7s/epoch - 723ms/step\n",
      "Test accuracy: 0.48846152424812317\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_images_data, test_annotations_data, verbose=2)\n",
    "print(f\"Test accuracy: {test_acc}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
