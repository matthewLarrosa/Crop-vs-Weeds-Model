{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout, InputLayer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_crop_weeds = 'agri_data/data/'  # Update this path as necessary\n",
    "\n",
    "# Images Sizes\n",
    "img_height = 512\n",
    "img_width = 512\n",
    "\n",
    "# Defines batch size and number of epochs\n",
    "batch_size = 32\n",
    "epochs = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Images: 1300\n",
      "Total Annotations: 1300\n"
     ]
    }
   ],
   "source": [
    "images = []\n",
    "annotations = []\n",
    "\n",
    "for filename in os.listdir(dataset_crop_weeds):\n",
    "    if filename.endswith('.jpeg'):\n",
    "        image_path = os.path.join(dataset_crop_weeds, filename)\n",
    "        images.append(image_path)\n",
    "    elif filename.endswith('.txt'):\n",
    "        annotation_path = os.path.join(dataset_crop_weeds, filename)\n",
    "        annotations.append(annotation_path)\n",
    "\n",
    "print(f\"Total Images: {len(images)}\")\n",
    "print(f\"Total Annotations: {len(annotations)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images, test_images, train_annotations, test_annotations = train_test_split(images, annotations, test_size=0.2, random_state=42)\n",
    "train_images, val_images, train_annotations, val_annotations = train_test_split(train_images, train_annotations, test_size=0.1, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_image(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB\n",
    "    image = cv2.resize(image, (img_width, img_height))\n",
    "    return image / 255.0  # Normalize pixel values to [0, 1]\n",
    "\n",
    "def parse_annotation(annotation_path):\n",
    "    with open(annotation_path, 'r') as file:\n",
    "        first_line = file.readline().strip()\n",
    "        class_label = int(first_line.split()[0])  # Extracts the class label\n",
    "    return class_label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_data = np.array([load_and_preprocess_image(img) for img in train_images])\n",
    "val_images_data = np.array([load_and_preprocess_image(img) for img in val_images])\n",
    "test_images_data = np.array([load_and_preprocess_image(img) for img in test_images])\n",
    "\n",
    "train_annotations_data = np.array([parse_annotation(ann) for ann in train_annotations])\n",
    "val_annotations_data = np.array([parse_annotation(ann) for ann in val_annotations])\n",
    "test_annotations_data = np.array([parse_annotation(ann) for ann in test_annotations])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_gen_args = dict(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest')\n",
    "\n",
    "train_datagen = ImageDataGenerator(**data_gen_args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    InputLayer(input_shape=(img_height, img_width, 3)),\n",
    "    Conv2D(32, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "30/30 [==============================] - 109s 4s/step - loss: 2.4388 - accuracy: 0.4754 - val_loss: 0.6932 - val_accuracy: 0.4712\n",
      "Epoch 2/10\n",
      "30/30 [==============================] - 95s 3s/step - loss: 0.6932 - accuracy: 0.5011 - val_loss: 0.6931 - val_accuracy: 0.5288\n",
      "Epoch 3/10\n",
      "30/30 [==============================] - 106s 3s/step - loss: 0.6931 - accuracy: 0.5128 - val_loss: 0.6930 - val_accuracy: 0.5288\n",
      "Epoch 4/10\n",
      "30/30 [==============================] - 102s 3s/step - loss: 0.6931 - accuracy: 0.5118 - val_loss: 0.6929 - val_accuracy: 0.5288\n",
      "Epoch 5/10\n",
      "30/30 [==============================] - 96s 3s/step - loss: 0.6930 - accuracy: 0.5118 - val_loss: 0.6928 - val_accuracy: 0.5288\n",
      "Epoch 6/10\n",
      "30/30 [==============================] - 102s 3s/step - loss: 0.6931 - accuracy: 0.5118 - val_loss: 0.6928 - val_accuracy: 0.5288\n",
      "Epoch 7/10\n",
      "30/30 [==============================] - 89s 3s/step - loss: 0.6931 - accuracy: 0.5118 - val_loss: 0.6928 - val_accuracy: 0.5288\n",
      "Epoch 8/10\n",
      "30/30 [==============================] - 89s 3s/step - loss: 0.6930 - accuracy: 0.5118 - val_loss: 0.6927 - val_accuracy: 0.5288\n",
      "Epoch 9/10\n",
      "30/30 [==============================] - 98s 3s/step - loss: 0.6930 - accuracy: 0.5118 - val_loss: 0.6927 - val_accuracy: 0.5288\n",
      "Epoch 10/10\n",
      "30/30 [==============================] - 106s 3s/step - loss: 0.6930 - accuracy: 0.5118 - val_loss: 0.6927 - val_accuracy: 0.5288\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_datagen.flow(train_images_data, train_annotations_data, batch_size=batch_size),\n",
    "    epochs=epochs,\n",
    "    validation_data=(val_images_data, val_annotations_data),\n",
    "    callbacks=[early_stopping]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 - 7s - loss: 0.6930 - accuracy: 0.5077 - 7s/epoch - 779ms/step\n",
      "Test accuracy: 0.5076923370361328\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_images_data, test_annotations_data, verbose=2)\n",
    "print(f\"Test accuracy: {test_acc}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
